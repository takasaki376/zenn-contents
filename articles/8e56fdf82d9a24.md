---
title: "Deep Learning資格試験 応用数学 確率・統計（２）"
emoji: "🍣"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: true
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 統計的推定

## 参考

[最尤推定量とは？初めての人にもわかる解説](https://ai-trend.jp/basic-study/estimator/maximum-likelihood-estimation/)

<!--[ベイズ統計学とは？初心者向けのやさしい解説](https://ai-trend.jp/basic-study/basic/bayesian-statistics/)-->
<!--[ベイズ推定と最尤推定の違いを例題を用いて解説](https://ai-trend.jp/basic-study/bayes/maximum-likelihood-estimation-bayes-estimator/)-->

<!--## 一致推定量-->

<!--## 不偏推定量-->

## 最尤推定

- パラメータ$\theta$に従う分布の密度関数を $f(x;\theta)$ とする。尤度関数を $L(\theta;x)=f(x;\theta)$ とすると、$L(\theta;x)$を最大にするような推定量 $\theta=\hat{\theta}$ を $\theta$ の最尤推定量という。
- 密度関数 $f(x;\theta)$ は、$\theta$を固定した上で$x$の関数である。
- 尤度関数 $L(\theta;x)$ は、$x$を固定した上で$\theta$の関数である。
- 対数尤度関数が最大となる$\theta$が最尤推定量となる。対数尤度関数を$\theta$で偏微分した値が$0$となる点のこと。

### ベルヌーイ分布に従うの場合の最尤推定量の導出

- {0,1}を取りうる２値のデータ$D=\{x_1, \dots,x_n\}$がベルヌーイ分布$f(x;p)=p^x(1-p)^{1-x}$に独立に従うと仮定する。
- この時最尤推定によって、パラメータ$p$を決定する。

尤度関数は、

$$
\begin{aligned}
  L_D(p) &= \prod_{i=1}^n f(x;p) \\[12px]
  &=  \prod_{i=1}^n p^{x_i}(1-p)^{1-x}
\end{aligned}
$$

となる。
対数尤度関数は、

$$
\begin{aligned}
  -\log L_D(p) &= -\log \prod_{i=1}^n f(x;p) \\[12px]
  &= -\sum_{i=1}^n \log f(x;p) \\[12px]
  &= -\sum_{i=1}^n \log p^{x_i}(1-p)^{1-x}  \\[12px]
  &= -\sum_{i=1}^n (x_i \log p + (1-x_i) \log (1-p))
\end{aligned}
$$

となる。この式は２クラス分類での損失関数に使用される交差エントロピーである。

### 二項分布に従うの場合の最尤推定量の導出

- コインを$n$回投げて、表が$x$回出た時の最尤推定
- 二項分布の密度関数($\theta$は固定値、$x$を求める)

$$
  f(x;\theta)={}_nC_x\theta^x(1−\theta)^{n−x}
$$

- 二項分布の場合の尤度関数($x$は固定値、$\theta$を求める)
- この関数が最大となる$\theta$を求める事が最尤推定量を求めることになる。

$$
  L(\theta;x)={}_nC_x\theta^x(1−\theta)^{n−x}
$$

- 尤度関数を微分すると最大値を求める事ができますが、計算が面倒なので対数尤度関数を微分します。
- 対数尤度関数

$$
\begin{aligned}
  l(\theta) &= logL(\theta;x) \\[10px]
  &= log \left[ {}_nC_x\theta^x(1−\theta)^{n−x} \right] \\[10px]
  &= log \left[ \frac{n!}{x!(n-x)!} \theta^x(1−\theta)^{n−x} \right] \\[10px]
  &= log(n!) - log(x!) - log(n-x)! + xlog\theta + (n-x)log(1-\theta)
\end{aligned}
$$

- これを微分する。

$$
\begin{aligned}
  \frac{d}{d\theta} l(\theta) &=  \frac{x}{\theta} + \frac{n-x}{1-\theta} \\[10px]
  &= \frac{x(1-\theta)-(n-x)\theta}{\theta(1-\theta)} \\[10px]
  &= \frac{x-x\theta-n\theta+x\theta}{\theta(1-\theta)} \\[10px]
  &= \frac{x-n\theta}{\theta(1-\theta)}
\end{aligned}
$$

- これが０になる時が最大となるため

$$
\begin{aligned}
  \frac{x-n\theta}{\theta(1-\theta)} &= 0 \\[10px]
  x-n\theta &= 0 \\[10px]
  x &= n\theta \\[10px]
  \theta &= \frac{x}{n}
\end{aligned}
$$

- コインを１０回（$n$）投げた時に、表が８回（$x$）投げた時の最尤推定量は、

$$
\begin{aligned}
  \theta &= \frac{8}{10} \\[10px]
  &= \frac{4}{5}
\end{aligned}
$$

<!--## ベイズ推定-->

# メモ

## 対数

$$
\begin{aligned}
 \log_2 0.125 &= -3 \\
 \log_2 0.25 &= -2 \\
 \log_2 0.5 &= -1 \\
 \log_2 1 &= 0 \\
 \log_2 2 &= 1
\end{aligned}
$$

## 総和

$$
  \sum_{i=1}^n a_i = a_1 + a_2 + a_3 + \dots + a_n
$$

## 総乗

$$
  \prod_{i=1}^n a_i = a_1 \times a_2 \times a_3 \times \dots \times a_n
$$

## 微分

$$
  (x^n)' = nx^{n-1}
$$

$$
  (e^x)' = e^x
$$

$$
  (a^x)' = a^x log_e a
$$

$$
  (log_e x)' = \frac{1}{x}
$$

$$
  (log_a x)' = \frac{1}{x \log_e a}
$$

## 積分

$$
  \int x^n dx = \frac{1}{n+1} x^{n+1} + C
$$
