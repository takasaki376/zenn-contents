---
title: "Deep Learning資格試験 機械学習 評価関数"
emoji: "🍣"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: false
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 混同行列

|                |                             陽性                             |                             陰性                             |
| :------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 予測結果が陽性 |  真陽性<br>True Positive<br>正しく positive と判別した個数   | 偽陰性<br>False Positive<br>間違えて positive と判別した個数 |
| 予測結果が陰性 | 擬陽性<br>False Negative<br>間違えて Negative と判別した個数 |  真陰性<br>True Negative<br>正しく Negative と判別した個数   |

# 正解率（accuracy）

- 分類問題で使用する
- 全てのデータのうち、正しく予測できた割合
- ０～１の範囲であり、１に近づくほど性能がよい

$$
Accuracy = \frac{TP+TN}{TP+TN+FN+FP}
$$

# 適合率（precision）

- 分類問題で使用する
- 陽性と予測したもののうち、実際に陽性であるものの割合
- ０～１の範囲であり、１に近づくほど性能がよい

$$
Precision = \frac{TP}{TP+FP}
$$

# 再現率（recall）

- 分類問題で使用する
- 実際に陽性であるもののうち、正しく陽性と予測できたものの割合
- 全て陽性と予測すると１になるため、単独では用いず適合率と合わせて評価する
- ０～１の範囲であり、１に近づくほど性能がよい

$$
Recall = \frac{TP}{TP+FN}
$$

# Ｆ値（F-measure）

- Recall と Precision の調和平均
- この値が大きいほど Recall と Precision の両方が良い事を示す。

$$
F\textrm-measure = \frac{2 \cdot Recall \cdot Precision}{Recall+Precision}
$$

# 特異度（specificity）

- 実際に陰性であるもののうち、正しく陰性と予測できたものの割合
- 再現率の正負を反転させた指標

$$
Specificity = \frac{TN}{TN+FP}
$$

# 偽陽性率 (False Positive Rate、FPR)

- 実際には陰性であるもののうち、誤って陽性と予測したものの割合
- 偽陽性率は「1 ー (特異度）」で求めることもできる。

$$
FPR = \frac{FP}{TN+FP}
$$

# ROC 曲線

- 横軸を Falsepositive rete(FPR)、縦軸を True positive rate(TPR)としたグラフを描く。
- ROC 曲線において、良いモデルとされるのは FPR が**小さい**とき、TPR が**大きい**モデルである。
- ROC 曲線の右下に囲まれた面積で求めることができ、**AUC**とよぶ。
- **AUC**は、０から１の値をとり、１に近いほど判別性能が高い事を示す。

# 平均絶対誤差（Mean Absolute Error 、MAE）

- 回帰で使用する。

$$
MAE = \frac{1}{n} \sum_{i=1}^n |f_i-y_i|
$$

# 平均二乗誤差（Mean Squared Error 、MSE）

- 回帰で使用する。

$$
  MSE = \frac{1}{n} \sum_{i=1}^n (f_i-y_i)^2
$$

# 平均二乗誤差平方根（Root Mean Squared Error 、RMSE）

- 回帰で使用する。

$$
  RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n (f_i-y_i)^2}
$$
