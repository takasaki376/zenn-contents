---
title: "Deep Learning資格試験 機械学習（２）"
emoji: "💭"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: true
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# ハイパーパラメータ探索

## グリッドサーチ

- ハイパーパラメータごとに候補点を設定し、そのすべての組み合わせを探索する。
- 全ての組み合わせを試すため、各ハイパーパラメータの候補点が多いほど、探索開始から探索終了までの時間が長くなります。

## ランダムサーチ

- 指定された各ハイパーパラメータの範囲で、探索点で、探索点をランダムに選択しながら探索を進める方法である。
- 探索の回数は任意に設定ができる。
- 探索対象となるハイパーパラメータの中に、性能に影響を与えないハイパーパラメータや連続値のハイパーパラメータが含まれる場合は、グリッドサーチに比べ、少ない探索回数で良い性能を示す点を見つけられる場合がある。
- 探索点はランダムに選ばれるため、同じような場所を何度も探索してしまうことや、見込みの低い場所を探索してしまうなどの非効率な探索を行う事もある。

## ベイズ最適化

- 探索を始めてから現時点までの探索結果を用いて評価指標の値を予測するモデルを構築し、その予測モデルと獲得関数を用いて、次の探索点を選択する方法である。
- 予測モデルには、ガウス過程回帰がよく用いられる。

# 正則化（パラメータノルムペナルティー）

- 過学習を抑えるために、線形回帰やニューラルネットワークにて用いられる。
- 正則化の対象とするパラメータにはバイアスを含むべきではない。大きくなることで過剰適合となることは少ないため。
- 正則化係数を大きくしすぎると、過剰適合ではなく、過少適合の傾向が表れる。

## L2 正則化（リッジ回帰）

- 正則化係数を十分に大きくすると、いくつかの回帰係数は０に近づくが、完全に０とはならない。

$$
\begin{aligned}
  \sqrt{J(\theta) + \lambda \sum_i \theta^2}
\end{aligned}
$$

## L1 正則化（ラッソ回帰）

- 特徴選択を目的に用いられる。
- 正則化係数を十分に大きくすると、完全に０となる。

$$
\begin{aligned}
  J(\theta) + \lambda \sum_i | \theta |
\end{aligned}
$$

## エラスティックネット

**L2 正則化**と**L1 正則化**を組み合わせた線形回帰のこと
