---
title: "Deep Learning資格試験 機械学習"
emoji: "🐕"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: false
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 学習アルゴリズム

- Michell（1997）によって定義された機械学習の定義である。
- タスクＴ、性能指標Ｐ、経験Ｅによって定義されている。

## タスクＴ

- 何をしたいかを指す概念である。
- どのように事例（データ）を実行すべきか
- 学習はタスクを実行する能力を獲得する手段であり、学習過程そのものはタスクでない。
- タスクの例
  - 分類
  - 回帰
  - 転写（構造化されていないデータを変換する問題。文字認識や音声認識など。）
  - 翻訳
  - 構造出力（入力データの構造を推定する問題。自然言語処理など。）
  - 異常検知
  - 合成とサンプリング
  - 欠陥値補完
  - ノイズ除去
  - 密度推定

## 性能指標Ｐ

- `精度`や`誤差`といった指標
- 性能指標の例
  - 正解率（accuracy）
  - 平均絶対誤差
  - 平均二乗誤差

## 経験Ｅ

- Michell（1997）では、データ集合自体を経験と呼ぶ。
- Goodfellow et al.（2018）では、「機械学習アルゴリズムはデータ集合を経験する」という。

# 前処理

## 欠損処理

- 欠損値がある場合に補完するか、説明変数として使用しないようにする。
- 時系列データの場合は、前後の値を用いて線形補間を行うことが多い。

## 外れ値除去

- 外れ値がある場合に補完するか、説明変数として使用しないようにする。

## 正規化

- 最小値０、最大値１に変換する

## 標準化

- 平均０、標準偏差１に変換する。
- 外れ値を含んでいると、標準化する際に用いる標準偏差の値が過大に評価されてしまうため、外れ値を除去してから標準化を行う方が適切に評価できる。

```python:python
# X  入力データ
import numpy as np

mean = X.mean(axis=0)
std =  X.std(axis=0)
Xsd = (X - mean) / atd
```

## アンダーサンプリング

- 一部のデータの件数が多い場合に、件数の多いクラスのみうまく分類できてしまう。
- 件数の多いデータのサンプルを減らす事をアンダーサンプリングという。

## ダミー変数化（one hot encoding）

- カテゴリデータを数値データに変換する。

## バッグオブワーズ

- 文書における単語の出現頻度を数えて頻度ベクトルで表現する方法。

## 特徴選択

### フィルタ法

- 学習を伴わずに、特徴量の重要度を測定して、有効な特徴量を選択する手法。
- 重要度には相関係数などが用いられる。
- 良い特徴が選択されるかどうかはその重要度に依存する。

### ラッパー法

- 学習と変数選択を何度も繰り返す事で最適な特徴量の組み合わせを探す手法。
- 計算に時間はかかるが検証誤差の小さい特徴量の組み合わせを見つけやすい。

### 埋め込み法

- ラッソなどの手法を用いて学習と同時に最適な特徴量の組み合わせを見つける手法。
- フィルタ法とラッパー法の中間的な性質。

# モデルの学習方法

## ホールドアウト法

- データを学習用とテスト用の 2 つに分割し、「予測精度」や「誤り率」を推定する為に使用する。
- 全てのデータを学習データにしてしまうと、過学習となる。
- 手元にデータが大量にある場合を除いて、良い性能評価を与えないという欠点がある。

## クロスバリデーション（K-分割交差検証）

参考：[交差検証（クロスバリデーション）とは？合わせてグリッドサーチに関しても学ぼう！](https://aiacademy.jp/media/?p=263)
[【AI・機械学習】ホールドアウト検証と K 分割交差検証(K-fold クロスバリデーション)｜モデル性能の評価](https://di-acc2.com/analytics/ai/6498/)

- データを K 個に分割してそのうち 1 つをテストデータに残りの K-1 個を学習データとして正解率の評価を行う。これを K 個のデータすべてが 1 回ずつテストデータになるように K 回学習を行なって精度の平均をとる手法である。
- データの偏りが発現しずらいほど十分なデータ量を使用している場合は、K の値を小さくすると良い。k の値が大きくなりすぎると、検証に対する計算コストが増大する。
- 小さなデータセットを扱う場合は、K の値を大きくすると良い。イテレーション数 k 回の繰り返しで利用される学習データが増えるため、汎化性能の評価に対する偏り(バイアス)を低く抑えることができる。

# 機械学習の性能評価

参考：[バイアス-バリアンス分解：機械学習の性能評価](https://www.hellocybernetics.tech/entry/2017/01/24/100415)

## 未学習

- 学習が不十分なために、データを表現するモデルが全く得られていないような状態である。
- 通常、訓練誤差が十分に減少していなければ未学習だといえる。

## 過学習

- 未知の新たなるデータを入力した際の予測性能が著しく低い。
- 訓練誤差を下げることに集中しすぎてしまい、与えた訓練データを「無理やり」表現するようなモデルになってしまった状態。

## バイアス-バリアンス分解

- バイアス-バリアンス分解は未学習や過学習の状況を理論的に解析する手法
- バイアス：モデルの表現力が不足していることによって生じる誤差　 ⇒ 　未学習
- バリアンス：訓練データの選び方によって生じる誤差
- ノイズ：データの測定誤差などによって生じる誤差
- バイアスとバリアンスはトレードオフ
  - モデルの複雑性（表現力）が大きくなると、バイアスは小さくなるが、バリアンスは大きくなる
