---
title: "Deep Learning資格試験 深層学習 CNN 代表的なモデル"
emoji: "🐈"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: true
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 画像分類モデル

## AlexNet

- 2012 年に考案されたモデル
- 8 層

## VGG

- 2014 年に考案されたモデル
- 19 層
- フィルタサイズ３ × ３の畳み込み層を複数積み重ねることで、少ないパラメータで大きなフィルタを使用した場合と同じ範囲を畳み込むことを提案したモデル

## GoogLeNet

[論文](https://arxiv.org/pdf/1409.4842.pdf)

- 2014 年に考案されたモデル
- 22 層
- Global Average Pooling というプーリングの手法を採用している。各チャンネルの画素平均値を求め、それをチャンネルの平均値を要素とするベクトルに変換する。この結果は、次の演算でチャンネルごとの特徴量として計算されることにより、全結合層ですべての画素値を使う場合と比べて大幅に計算量を削減できる。

### インセプションモジュール

- フィルタサイズの異なる畳み込みを並列に行って、その出力を足し合わせることで、複数のスケールの特徴を抽出することができるようになり、層を深くして複雑な特徴を表現できるようになった。
- $1 \times 1$の畳み込みフィルタを有しているが、次元削減としての側面を持つ

### auxiliary classifiers

- ネットワークの途中で分岐させたサブネットワークで予測を行う補助的分類器といった工夫が導入されている。
- アンサンブル学習と同様の効果が得られるため、汎化性能の向上が期待できる。

## ResNet (Residual Network)

[論文](https://arxiv.org/pdf/1512.03385.pdf)

- 2015 年に考案されたモデル
- 152 層
- 特徴マップ同士を足し合わせるショートカット結合が特徴的なモデル
- 層を深くすると勾配消失が起こるが、ResNet は勾配消失が起こりにくい
- 浅い CNN で十分学習できてしまい、深い中間層が不要な場合、不要な層の重みが０になる。
- 入力時点の勾配が小さい場合、通常であればレイヤーを重ねていくほど勾配が消失してしまうが、スキップコネクションを通す事によってわずかな勾配の乗法も消失することなく残すがことができる。

### identity mapping (Skip connection)

![identity](https://storage.googleapis.com/zenn-user-upload/a542d194023f-20220208.jpg)

- 層が深いネットワークでも学習が進められる

## DenseNet

- 恒等画像を介して特徴マップ同士を足し合わせるショートカット結合
- あるブロック内ですでに作られた特徴マップ全てを対象とします。

:::details DenseNet 詳細

### Dense Block

#### 出⼒層に前の層の⼊⼒を⾜しあわせる

- 層間の情報の伝達を最⼤にするために全ての同特徴量サイズの層を結合する

#### 特徴マップの⼊⼒に対し、下記の処理で出⼒を計算

- Batch 正規化
- Relu 関数による変換
- 3 x 3 畳み込み層による処理

#### k をネットワークの growth rate と呼ぶ

- k が⼤きくなるほど、ネットワークが⼤きくなるため、⼩さな整数に設定するのがよい

### Transition Layer

- CNN では中間層でチャネルサイズを変更し
- 特徴マップのサイズを変更し、ダウンサンプリングを⾏うため、Transition Layer と呼ばれる層で Dence block をつなぐ

### DenseNet と ResNet の違い

- DenseBlock では前⽅の各層からの出⼒全てが後⽅の層への⼊⼒として⽤いられる
- RessidualBlock では前 1 層の⼊⼒のみ後⽅の層へ⼊⼒

### 正規化

#### Batch Norm

- ミニバッチに含まれる sample の同⼀チャネルが同⼀分布に従うよう正規化
- H x W x C の sample が N 個あった場合に、N 個の同⼀チャネルが正規化の単位
- RGB の 3 チャネルの sample が N 個の場合は、それぞれのチャンネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。チャンネルごとに正規化された特徴マップを出⼒。
- Batch Normalization はニューラルネットワークにおいて学習時間の短縮や初期値への依存低減、過学習の抑制など効果がある。
- 問題点
- Batch Size が⼩さい条件下では、学習が収束しないことがあり、代わりに Layer Normalization などの正規化⼿法が使われることが多い。

#### Layer Norm

- それぞれの sample の全ての pixels が同⼀分布に従うよう正規化
- N 個の sample のうち⼀つに注⽬。H x W x C の全ての pixel が正規化の単位。
- RGB の 3 チャネルの sample が N 個の場合は、ある sample を取り出し、全てのチャネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。特徴マップごとに正規化された特徴マップを出⼒
- ミニバッチの数に依存しないので、上記の問題を解消できていると考えられる。

#### Instance Nrom

- さらに channel も同⼀分布に従うよう正規化
- 各 sample をチャンネルを ごとに正規化
- コントラストの正規化に寄与・画像のスタイル転送やテクスチャ合成タスクなどで利用

:::

# 物体検出モデル

## MobileNet

- スマートフォンのような計算資源が限られた環境下で利用するために
- 通常の畳み込みの代わりにデブスワイズ畳み込みと、ポイントワイズ畳み込みの２種類の畳み込みを採用している。

- Depthwise Separable Convolution という⼿法を⽤いて計算量を削減している。通常の畳込みが空間⽅向とチャネル⽅向の計算を同時に⾏うのに対して、Depthwise Separable Convolution ではそれらを Depthwise Convolution と Pointwise Convolution と呼ばれる演算によって個別に⾏う。
- Depthwise Convolition はチャネル毎に空間⽅向へ畳み込む。すなわち、チャネル毎に$D_K \times D_K \times 1$のサイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \times W \times C \times D_K \times D_K $となる。
- 次に Depthwise Convolution の出⼒を Pointwise Convolution によってチャネル⽅向に畳み込む。すなわち、出⼒チャネル毎に$1 \times 1 \times M$サイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \times W \times C \times M$となる。

### Depthwise Convolution（デブスワイズ畳み込み）

- ⼊⼒マップのチャネルごとに畳み込みを実施
- 出⼒マップをそれらと結合 (⼊⼒マップのチャネル数と同じになる)

チャンネルごとに畳み込みをするため、チャンネル間の関連性は考慮されない。

入力マップ：$H \times W \times C$ \
カーネル：$K \times K \times 1$ （フィルタ数は１固定）\
出力マップ：$H \times W \times C$

出力マップの計算量は：$H \times W \times C \times K \times K$

### Pointwise Convolution（ポイントワイズ畳み込み）

- 1 x 1 conv とも呼ばれる (正確には 1 x 1 x c)
- ⼊⼒マップのポイントごとに畳み込みを実施
- 出⼒マップ(チャネル数)はフィルタ数分だけ作成可能 (任意のサイズが指定可能)

入力マップ：$H \times W\times C$ \
カーネル：$1 \times 1 \times C$ \
出力マップ：$H \times W \times M$

出力マップの計算量は：$H\times W\times C\times M$

### ダイレクト畳み込み

- セマンティックセグメンテーションのように広い領域を参照しなければならないタスクの場合、単にフィルタサイズを大きくするとパラメータ数が増加するため、計算量が増加する。少ないパラメータ数で広い領域を参照できる畳み込み

### 転置畳み込み

- 生成モデルのようにアップサンプリングを行う場合に使う畳み込み

### 通常の CNN との比較

[CCN の計算量](https://zenn.dev/takasaki/articles/f7c99060d621a7#%E8%A8%88%E7%AE%97%E9%87%8F)

#### CCN の計算量

入力チャンネル数:$C_{in}$
出力チャンネル数:$C_{out}$
フィルタサイズの高さ:$F_h$
フィルタサイズの幅:$F_w$
計算量:$C_{in}C_{out}F_hF_w$

#### デブスワイズ畳み込みの計算量

計算量:$\frac{1}{C_{out}}$

#### ポイントワイズ畳み込みの計算量

計算量:$\frac{1}{F_hF_w}$

## R-CNN

- 2014 年に考案されたモデル
- 画像内に存在する複数の物体をそれぞれ個別に検出したい。
- CNN から出力された特徴マップを SVM に入力しカテゴリ識別を行い、回帰によって正確な領域の推定を行う。
- 特徴抽出の CNN、カテゴリ推定の SVM など各学習の目的ごとに別々に学習させる必要があるため、End-to-End 学習ができない。
- CNN の入力層のサイズは$227 \times 227pixel$固定である。CNN に渡される前にリサイズをするがアスペクト比は保たれない。

### Region Proposal(物体候補領域検出)

- 領域候補を取得するために Selective Search（選択的探索法）を用いる。

## Faster R-CNN

[論文](https://arxiv.org/pdf/1506.01497.pdf)

- 誤差関数には**Anchor**が取り入れられている。
- 分類を行う層への入力を固定次元にするために**RoI Pooling**を行っている。

### Region Proposal(物体候補領域検出)

- 領域候補を取得するためにニューラルネットワークを用いる。
