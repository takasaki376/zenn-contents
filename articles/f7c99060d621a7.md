---
title: "Deep Learning資格試験 深層学習 畳み込みニューラルネットワーク"
emoji: "🌊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: true
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 畳み込み層

- 入力データからフィルタを使いタスクを解くために有用な特徴を抽出する。

# プーリング層

- ある範囲ごとに最大値や平均値を取ることで、入力データの微小な位置変化に対してほぼ不変な表現を出力することができる。

プーリングは、縦・横方向の空間を小さくする演算である。プーリング層には以下の特徴がある。

## 学習するパラメータがない

- プーリング層は、畳み込み層と違って学習するパラメータを持たない。プーリングは、対象領域から最大値を得る（もしくは平均を取る）だけの処理なので、学習すべきパラメータは存在しない。

## チャンネル数は変化しない

- プーリングの演算によって、入力データと出力データのチャンネル数は変化しない。

# ストライド

- フィルターを適用する位置の間隔をストライド（stride）という。
- ストライドを２にすると、フィルターを適用する窓の間隔が２要素ごとになる。

# パディング

- 畳み込み層の処理を行う前に、入力データの周囲に固定のデータ（たとえば０など）を埋めること。

# 畳み込み層の出力画像サイズの計算

- 入力サイズの高さ：$H$
- 入力サイズの幅：$W$
- フィルタの高さ：$FH$
- フィルタの幅：$FW$
- パディング：$P$
- ストライド：$S$

- 出力画像の高さ：

$$
  \frac{H + 2 \times P - FH}{S} + 1
$$

- 出力画像の幅：

$$
  \frac{W + 2 \times P - FW}{S} + 1
$$

# 計算量

- 入力マップ：$H \times W \times C$
- カーネル：$K \times K \times C$
- 出力マップ：$H \times W \times M$

ストライド１でパディングありの場合の１つの点での計算量は、$K \times K \times C \times M$ \
出力マップ全体すると、$H \times W \times K \times K \times C \times M$

# Attention

# データセット

| 名称      | クラス | Train+Val | BOX/画像 |    画像サイズ    | Ground-Truth BB |
| :-------- | :----: | :-------: | :------: | :--------------: | :-------------: |
| VOC12     |   20   |  11,540   |   2.4    | $470 \times 380$ |   左上と右下    |
| ILSVRC17  |  200   |  476,668  |   1.1    | $500 \times 400$ |                 |
| MS COCO18 |   80   |  123,287  |   7.3    | $640 \times 480$ |                 |
| OICOD18   |  500   | 1,743,042 |   7.0    |    一様でない    |                 |

- VOC12：Visual Object Classes
- ILSVRC17：ImageNet Scale Visual Recognition Challenge
- MS COCO18：MS Common Object in Context
- OICOD18：Open Images Challenge Object Detection

# 評価関数

## IoU

- ボックスの重なりを評価するための指標

$$
\begin{aligned}
  IoU &= \frac{TP}{TP+FP+FN}\\[12px]
  &= \frac{Area \hspace{2mm} of \hspace{2mm} Overlap}{Area \hspace{2mm} of \hspace{2mm} Union}
\end{aligned}
$$

## AP

- 予測した各ボックスについて True と False を判定でき、通常のニューラルネットワークと同様に各クラスについて適合率や再現率を計算することができる。

$$
\begin{aligned}
    AP = \int_0^1 P(R)dR
\end{aligned}
$$

## mAP

- AP は各クラスに対して計算できる。
- モデル全てのクラスに対して AP を算出し、平均を取った値

$$
\begin{aligned}
    mAP = \frac{1}{C} \sum_{i=1}^C AP_i
\end{aligned}
$$

# im2col

ソースコードは[ゼロから作る Deep Learning](https://www.oreilly.co.jp/books/9784873117584/)から引用

```python:pytyhon
def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
    """
    Parameters
    ----------
    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ
    filter_h : フィルターの高さ
    filter_w : フィルターの幅
    stride : ストライド
    pad : パディング
    Returns
    -------
    col : 2次元配列
    """
    N, C, H, W = input_data.shape

    # 出力サイズの計算
    out_h = (H + 2*pad - filter_h)//stride + 1
    out_w = (W + 2*pad - filter_w)//stride + 1

    # 入力画像のパディング
    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')

    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))

    # フィルタに対する画像をスライス
    for y in range(filter_h):
        y_max = y + stride*out_h
        for x in range(filter_w):
            x_max = x + stride*out_w
            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]

    # （画像枚数 * 畳み込み回数 * フィルタの要素数)の行列に変換
    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)
    return col
```
