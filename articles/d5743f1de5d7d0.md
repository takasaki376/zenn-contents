---
title: "Deep Learning資格試験 深層学習 CNN 代表的なモデル"
emoji: "🐈"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["E資格"]
published: false
---

# はじめに

日本ディープラーニング協会の Deep Learning 資格試験（E 資格）の受験に向けて、調べた内容をまとめていきます。

# 画像分類モデル

## AlexNet

- 2012 年に考案されたモデル

## VGG

- 2014 年に考案されたモデル
- フィルタサイズ３ × ３の畳み込み層を複数積み重ねることで、少ないパラメータで大きなフィルタを使用した場合と同じ範囲を畳み込むことを提案したモデル

## GoogLeNet

- 2014 年に考案されたモデル
- インセプションモジュールは、フィルタサイズの異なる畳み込みを並列に行って、その出力を足し合わせることで、複数のスケールの特徴を抽出することができるようになり、層を深くして複雑な特徴を表現できるようになった。
- ネットワークの途中で分岐させたサブネットワークで予測を行う補助的分類器といった工夫が導入されている。
- Global Average Pooling というプーリングの手法を採用している。各チャンネルの画素平均値を求め、それをチャンネルの平均値を要素とするベクトルに変換する。この結果は、次の演算でチャンネルごとの特徴量として計算されることにより、全結合層ですべての画素値を使う場合と比べて大幅に計算量を削減できる。

## ResNet

- 2015 年に考案されたモデル
- 特徴マップ同士を足し合わせるショートカット結合が特徴的なモデル

## Dense Net

- 特徴マップをチャンネル方向に結合するショートカット結合
- あるブロック内ですでに作られた特徴マップ全てを対象とします。

### Dense Block

#### 出⼒層に前の層の⼊⼒を⾜しあわせる

- 層間の情報の伝達を最⼤にするために全ての同特徴量サイズの層を結合する

#### 特徴マップの⼊⼒に対し、下記の処理で出⼒を計算

- Batch 正規化
- Relu 関数による変換
- 3 x 3 畳み込み層による処理

#### k をネットワークの growth rate と呼ぶ

- k が⼤きくなるほど、ネットワークが⼤きくなるため、⼩さな整数に設定するのがよい

### Transition Layer

- CNN では中間層でチャネルサイズを変更し
- 特徴マップのサイズを変更し、ダウンサンプリングを⾏うため、Transition Layer と呼ばれる層で Dence block をつなぐ

### DenseNet と ResNet の違い

- DenseBlock では前⽅の各層からの出⼒全てが後⽅の層への⼊⼒として⽤いられる
- RessidualBlock では前 1 層の⼊⼒のみ後⽅の層へ⼊⼒

### 正規化

#### Batch Norm

- ミニバッチに含まれる sample の同⼀チャネルが同⼀分布に従うよう正規化
- H x W x C の sample が N 個あった場合に、N 個の同⼀チャネルが正規化の単位
- RGB の 3 チャネルの sample が N 個の場合は、それぞれのチャンネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。チャンネルごとに正規化された特徴マップを出⼒。
- Batch Normalization はニューラルネットワークにおいて学習時間の短縮や初期値への依存低減、過学習の抑制など効果がある。
- 問題点
- Batch Size が⼩さい条件下では、学習が収束しないことがあり、代わりに Layer Normalization などの正規化⼿法が使われることが多い。

#### Layer Norm

- それぞれの sample の全ての pixels が同⼀分布に従うよう正規化
- N 個の sample のうち⼀つに注⽬。H x W x C の全ての pixel が正規化の単位。
- RGB の 3 チャネルの sample が N 個の場合は、ある sample を取り出し、全てのチャネルの平均と分散を求め正規化を実施 (図の⻘い部分に対応)。特徴マップごとに正規化された特徴マップを出⼒
- ミニバッチの数に依存しないので、上記の問題を解消できていると考えられる。

#### Instance Nrom

- さらに channel も同⼀分布に従うよう正規化
- 各 sample をチャンネルを ごとに正規化
- コントラストの正規化に寄与・画像のスタイル転送やテクスチャ合成タスクなどで利用

# 物体検出モデル

## YOLO

## SDD

## MobileNet

- スマートフォンのような計算資源が限られた環境下で利用するために
- 通常の畳み込みの代わりにデブスワイズ畳み込みと、ポイントワイズ畳み込みの２種類の畳み込みを採用している。

- Depthwise Separable Convolution という⼿法を⽤いて計算量を削減している。通常の畳込みが空間⽅向とチャネル⽅向の計算を同時に⾏うのに対して、Depthwise Separable Convolution ではそれらを Depthwise Convolution と Pointwise Convolution と呼ばれる演算によって個別に⾏う。
- Depthwise Convolition はチャネル毎に空間⽅向へ畳み込む。すなわち、チャネル毎に$D_K \times D_K \times 1$のサイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \times W \times C \times D_K \times D_K $となる。
- 次に Depthwise Convolution の出⼒を Pointwise Convolution によってチャネル⽅向に畳み込む。すなわち、出⼒チャネル毎に$1 \times 1 \times M$サイズのフィルターをそれぞれ⽤いて計算を⾏うため、その計算量は$H \times W \times C \times M$となる。

### Depthwise Convolution（デブスワイズ畳み込み）

- 仕組み
- ⼊⼒マップのチャネルごとに畳み込みを実施
- 出⼒マップをそれらと結合 (⼊⼒マップのチャネル数と同じになる)

チャンネルごとに畳み込みをするため、チャンネル間の関連性は考慮されない。

入力マップ：$H \times W \times C$ \
カーネル：$K \times K \times 1$ （フィルタ数は１固定）\
出力マップ：$H \times W \times C$

出力マップの計算量は：$H \times W \times C \times K \times K$

### Pointwise Convolution（ポイントワイズ畳み込み）

- 仕組み
- 1 x 1 conv とも呼ばれる (正確には 1 x 1 x c)
- ⼊⼒マップのポイントごとに畳み込みを実施
- 出⼒マップ(チャネル数)はフィルタ数分だけ作成可能 (任意のサイズが指定可能)

入力マップ：$H \times W\times C$ \
カーネル：$1 \times 1 \times C$ \
出力マップ：$H \times W \times M$

出力マップの計算量は：$H\times W\times C\times M$

## R-CNN

- 画像内に存在する複数の物体をそれぞれ個別に検出したい。

## Faster R-CNN
